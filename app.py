"""
Hugging Face Spaces ì§„ì…ì  (Gradio SDK)
FastAPI + Gradio í•˜ì´ë¸Œë¦¬ë“œ
"""

import gradio as gr
from fastapi import FastAPI
import uvicorn
from pathlib import Path
import sys

# ğŸ”¥ ì¡°ê±´ë¶€ spaces import
try:
    if sys.platform.startswith('linux'):
        import spaces
        HAS_SPACES = True
    else:
        class SpacesDummy:
            @staticmethod
            def GPU(duration=None):
                def decorator(func):
                    return func
                return decorator
        spaces = SpacesDummy()
        HAS_SPACES = False
except ImportError:
    class SpacesDummy:
        @staticmethod
        def GPU(duration=None):
            def decorator(func):
                return func
            return decorator
    spaces = SpacesDummy()
    HAS_SPACES = False

print(f"ğŸ” Platform: {sys.platform}")
print(f"ğŸ” ZeroGPU available: {HAS_SPACES}")

sys.path.insert(0, str(Path(__file__).parent))
from app.main import app as fastapi_app

# ============================================================================
# Startup GPU check (HF Spaces only)
# ============================================================================
@spaces.GPU(duration=5)
def _startup_gpu_check():
    """Startup GPU detection"""
    if HAS_SPACES:
        import torch
        return torch.cuda.is_available()
    return False

if HAS_SPACES:
    print(f"ğŸ” GPU Check: {_startup_gpu_check()}")

# ============================================================================
# Gradio Interface
# ============================================================================

def analyze_image(image, concerns):
    """Gradio interface - no GPU decorator"""
    import tempfile
    import os
    from PIL import Image
    import requests
    
    if image is None:
        return "âŒ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”"
    
    with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as tmp:
        if isinstance(image, Image.Image):
            image.save(tmp.name)
        else:
            Image.fromarray(image).save(tmp.name)
        tmp_path = tmp.name
    
    try:
        with open(tmp_path, 'rb') as f:
            files = {'file': ('image.jpg', f, 'image/jpeg')}
            data = {'concerns': concerns} if concerns else {}
            
            response = requests.post(
                'http://localhost:7860/api/v1/analysis/comprehensive',
                files=files,
                data=data,
                timeout=60
            )
        
        if response.status_code == 200:
            result = response.json()
            output = "## ğŸ“Š í”¼ë¶€ ë¶„ì„ ê²°ê³¼\n\n"
            
            if 'sensitivity' in result:
                sens = result['sensitivity']
                output += "### ğŸ§´ í”¼ë¶€ ë¯¼ê°ë„\n\n"
                
                if 'overall_sensitivity' in sens:
                    overall = sens['overall_sensitivity']
                    if isinstance(overall, dict):
                        output += f"- **ì¢…í•© ì ìˆ˜**: {overall.get('score', 'N/A')}\n"
                        output += f"- **ë ˆë²¨**: {overall.get('level', 'N/A')}\n\n"
                
                items = [
                    ('dryness', 'ê±´ì¡°ë„'),
                    ('pigmentation', 'ìƒ‰ì†Œì¹¨ì°©'),
                    ('pore', 'ëª¨ê³µ'),
                    ('elasticity', 'íƒ„ë ¥')
                ]
                
                for key, label in items:
                    if key in sens:
                        value = sens[key]
                        if isinstance(value, dict):
                            score = value.get('score', 'N/A')
                            level = value.get('level', '')
                            output += f"- **{label}**: {score}"
                            if level:
                                output += f" ({level})"
                            output += "\n"
                        elif isinstance(value, (int, float)):
                            output += f"- **{label}**: {value:.2f}\n"
                
                output += "\n"
            
            if 'ai_analysis' in result:
                ai = result['ai_analysis']
                output += "### ğŸ¤– AI ë·°í‹° ê°€ì´ë“œ\n\n"
                
                if 'summary' in ai and ai['summary']:
                    output += f"**ìš”ì•½**:\n{ai['summary']}\n\n"
                
                if 'recommendations' in ai and ai['recommendations']:
                    recs = ai['recommendations']
                    if isinstance(recs, list) and recs:
                        output += "**ì¶”ì²œì‚¬í•­**:\n"
                        for i, rec in enumerate(recs, 1):
                            output += f"{i}. {rec}\n"
            
            return output
        else:
            return f"âŒ ì—ëŸ¬ ë°œìƒ: {response.status_code}\n\n{response.text}"
    
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        return f"âŒ ë¶„ì„ ì‹¤íŒ¨: {str(e)}\n\nìƒì„¸:\n```\n{error_details}\n```"
    
    finally:
        if os.path.exists(tmp_path):
            os.remove(tmp_path)


# Gradio UI
with gr.Blocks(title="ì–¼êµ´ ë¶„ì„ API") as demo:
    gr.Markdown("""
    # ğŸ¨ ì–¼êµ´ ë¶„ì„ & í”¼ë¶€ ì§„ë‹¨ API
    
    NIA ëª¨ë¸ ê¸°ë°˜ í”¼ë¶€ ë¯¼ê°ë„ ë¶„ì„ + GPT ë·°í‹° ê°€ì´ë“œ
    """)
    
    with gr.Row():
        with gr.Column():
            image_input = gr.Image(label="ì–¼êµ´ ì´ë¯¸ì§€", type="pil", sources=["upload", "webcam"])
            concerns_input = gr.Textbox(label="í”¼ë¶€ ê³ ë¯¼ (ì„ íƒ)", lines=2)
            analyze_btn = gr.Button("ğŸ” ë¶„ì„ ì‹œì‘", variant="primary")
        
        with gr.Column():
            output = gr.Markdown(label="ë¶„ì„ ê²°ê³¼")
    
    analyze_btn.click(fn=analyze_image, inputs=[image_input, concerns_input], outputs=output)

# Mount FastAPI
app = gr.mount_gradio_app(fastapi_app, demo, path="/")

if __name__ == "__main__":
    print("ğŸš€ Starting Gradio + FastAPI server...")
    uvicorn.run(app, host="0.0.0.0", port=7860, log_level="info")